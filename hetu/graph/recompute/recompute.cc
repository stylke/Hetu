#include "hetu/graph/recompute/recompute.h"

namespace hetu {
namespace graph {

bool Recompute::_enabled = false;

// helper functions
namespace {
  inline int get_out_idx_of(const Operator& op, const Tensor& tensor) {
    auto num_output = op->num_outputs();
    for (int out_pos = 0; out_pos < num_output; out_pos++) {
      if (op->output(out_pos)->id() == tensor->id()) {
        return out_pos;
      }
    }
    return -1;
  }
} // namespace

bool Recompute::IsNoRecomputedOp(Operator& op) {
  if (is_comm_op(op)) {
    auto& comm_op = op;
    auto& comm_op_impl = reinterpret_cast<CommOpImpl&>(comm_op->body());
    uint64_t comm_type = comm_op_impl.get_comm_type(comm_op);
    return comm_type == PEER_TO_PEER_RECV_OP ||
           comm_type == PEER_TO_PEER_SEND_OP ||
           comm_type == BATCHED_ISEND_IRECV_OP;
  } else {
    return is_variable_op(op) ||
           is_placeholder_op(op);
  }
}

void Recompute::GetMaxRecomputeSubGraph(Op2OpRefMap& recompute_subgraph, bool get_inputs, bool get_outputs) {
  OpRefQueue to_visit;
  for (auto& op_opref : recompute_subgraph) {
    to_visit.push(op_opref.second);
  }
  recompute_subgraph.clear();

  while (!to_visit.empty()) {
    auto& op_ref = to_visit.front();
    to_visit.pop();
    if (recompute_subgraph.find(op_ref.get()->id()) != recompute_subgraph.end()) {
      continue;
    }
    recompute_subgraph.insert({op_ref.get()->id(), op_ref});
    // add recomputed inputs to recompute subgraph
    if (get_inputs) {
      auto& op_inputs = op_ref.get()->inputs();
      for (auto& input : op_inputs) {
        auto& op = input->producer();
        if (op->op_meta().is_recompute && !IsNoRecomputedOp(op) &&
            recompute_subgraph.find(op->id()) == recompute_subgraph.end()) {
          to_visit.push(std::ref(op));
        }
      }
    }
    // add recomputed outputs to recompute subgraph
    if (get_outputs) {
      auto& op_outputs = op_ref.get()->outputs();
      for (auto& output : op_outputs) {
        auto& out_consumers = output->consumers();
        for (auto& op_ref : out_consumers) {
          auto& op = op_ref.get();
          if (op->op_meta().is_recompute && !IsNoRecomputedOp(op) &&
              recompute_subgraph.find(op->id()) == recompute_subgraph.end()) {
            to_visit.push(op_ref);
          }
        }
      }
    }
  }
}

bool Recompute::HasFilterOpInPath(const Operator& op, std::function<bool(const Operator &)> filter_fn,
                                  std::unordered_map<OpId, bool>& has_filter_op_map) {
  if (has_filter_op_map.find(op->id()) != has_filter_op_map.end()) {
    return has_filter_op_map[op->id()];
  }
  if (filter_fn(op)) {
    has_filter_op_map.insert({op->id(), true});
    return true;
  }
  if (op->is_bw_op()) {
    auto& inputs = op->inputs();
    for (auto& input : inputs) {
      if (HasFilterOpInPath(input->producer(), filter_fn, has_filter_op_map)) {
        has_filter_op_map.insert({op->id(), true});
        return true;
      }
    }
  }
  has_filter_op_map.insert({op->id(), false});
  return false;
}

Operator& Recompute::DuplicateRecomputedOp(const Operator& origin_op, const Op2OpRefMap& filtered_recomputed_ops,
                                           const TensorList& first_mapped_grad_inputs, Op2OpMap& origin_to_recomputed_map,
                                           ExecutableGraph& cur_exec_graph) {
  auto iter = origin_to_recomputed_map.find(origin_op->id());
  if (iter != origin_to_recomputed_map.end()) {
    return iter->second;
  }
  TensorList new_inputs;
  bool has_recomputed_input = false;
  auto& origin_inputs = origin_op->inputs();
  for (auto& input : origin_inputs) {
    auto& input_op = input->producer();
    if (filtered_recomputed_ops.find(input_op->id()) == filtered_recomputed_ops.end()) {
      new_inputs.push_back(input);
    } else {
      has_recomputed_input = true;
      // find the output position of input in input_op
      auto out_idx = get_out_idx_of(input_op, input);
      HT_ASSERT(out_idx != -1)
        << "Cannot find input " << input << " in the outputs of recomputed op " << input_op;
      auto& new_input = DuplicateRecomputedOp(input_op, filtered_recomputed_ops,
                                              first_mapped_grad_inputs, origin_to_recomputed_map, cur_exec_graph);
      new_inputs.push_back(new_input->output(out_idx));
    }
  }
  auto new_op_meta = OpMeta().set(origin_op->op_meta())
                             .set_is_recompute(false)
                             .set_name(origin_op->name() + "_recompute")
                             .set_origin_op_id(origin_op->id());
  // add the execution dependency
  if (!has_recomputed_input) {
    new_op_meta.set_extra_deps(first_mapped_grad_inputs);
  }
  auto& new_op = Graph::MakeOp(origin_op->_body, std::move(new_inputs),
                               std::move(new_op_meta), cur_exec_graph);
  for (auto& output : new_op->outputs()) {
    cur_exec_graph.RecordTensorShape(output->id(), output->shape());
  }
  if (!origin_op->placement_group().empty())
    new_op->MapToParallelDevices(origin_op->placement_group());
  new_op->Instantiate(origin_op->instantiation_ctx().placement, 
                      origin_op->instantiation_ctx().stream_index);
  origin_to_recomputed_map.insert({origin_op->id(), new_op});
  return origin_to_recomputed_map[origin_op->id()];
}

void Recompute::InsertRecomputedOps(const OpRefList& topo_order) {
  // Find candidate recomputed ops.
  auto has_grad_consumer = [](const Tensor& tensor) {
    return Tensor::any_consumer_of(tensor, [](const OpRef& op_ref) -> bool {
      return op_ref.get()->is_bw_op();
    });
  };
  HT_LOG_DEBUG << "[Recompute] find candidate recomputed ops begin...";
  OpRefList candidate_recomputed_ops;
  for (auto& op_ref : topo_order) {
    auto& op = op_ref.get();
    if (!op->op_meta().is_recompute || IsNoRecomputedOp(op)) {
      continue;
    }
    // No recomputation if there is no grad op in the outputs
    if (Operator::any_output_tensor_of(op, has_grad_consumer)) {
      candidate_recomputed_ops.push_back(op_ref);
    }
  }
  HT_LOG_DEBUG << "[Recompute] Found " << candidate_recomputed_ops.size()
               << " candidate recomputed ops: " << candidate_recomputed_ops;
  // Iterate over all candidate recomputed ops and
  // construct recompute subgraph with continuous recomputed ops.
  OpIdSet visited_ops;
  for (auto& candidate_recomputed_op_ref : candidate_recomputed_ops) {
    auto& candidate_recomputed_op = candidate_recomputed_op_ref.get();
    if (visited_ops.find(candidate_recomputed_op->id()) != visited_ops.end()) {
      continue;
    }
    // Get max continuous recompute subgraph first.
    HT_LOG_DEBUG << "[Recompute] get max recomputed subgraph begin...";
    Op2OpRefMap max_recompute_subgraph = {{candidate_recomputed_op->id(), candidate_recomputed_op_ref}};
    GetMaxRecomputeSubGraph(max_recompute_subgraph, true, true);
    OpIdList max_recompute_subgraph_ids;
    for (auto& op : max_recompute_subgraph) {
      max_recompute_subgraph_ids.push_back(op.first);
    }
    visited_ops.insert(max_recompute_subgraph_ids.begin(), max_recompute_subgraph_ids.end());
    // Filter recomputed ops that directly output to grad ops.
    HT_LOG_DEBUG << "[Recompute] filter recomputed ops that directly output to grad ops begin...";
    Op2OpRefMap filtered_recomputed_ops;
    Op2OpRefMap mapped_grad_ops;
    for (auto& op_opref : max_recompute_subgraph) {
      bool inserted = false;
      auto op_id = op_opref.first;
      auto& op_ref = op_opref.second;
      auto& op_outputs = op_ref.get()->outputs();
      for (auto& output : op_outputs) {
        auto& out_consumers = output->consumers();
        for (auto& out_op_ref : out_consumers) {
          if (!out_op_ref.get()->is_bw_op()) {
            continue;
          }
          mapped_grad_ops.insert({out_op_ref.get()->id(), out_op_ref});
          if (!inserted) {
            inserted = true;
            if (filtered_recomputed_ops.find(op_ref.get()->id()) != filtered_recomputed_ops.end()) {
              continue;
            }
            filtered_recomputed_ops.insert({op_id, op_ref});
          }
        }
      }
    }
    // Get inputs of filtered recomputed ops which eventually output to grad ops.
    HT_LOG_DEBUG << "[Recompute] get inputs of filtered recomputed ops which eventually output to grad ops begin...";
    GetMaxRecomputeSubGraph(filtered_recomputed_ops, true, false);
    HT_LOG_DEBUG << "[Recompute] found continuous recompute subgraph: " << filtered_recomputed_ops;
    // Find inputs of the first mapped grad op in the topo order, these
    // inputs will be the execution dependencies of the recompute subgraph.
    HT_LOG_DEBUG << "[Recompute] find inputs of the first mapped grad op in the topo order begin...";
    TensorList first_mapped_grad_inputs;
    std::unordered_map<OpId, bool> has_filter_op_map;
    auto filter_fn = [&filtered_recomputed_ops, &mapped_grad_ops](const Operator& op) -> bool {
      return filtered_recomputed_ops.find(op->id()) != filtered_recomputed_ops.end() ||
             mapped_grad_ops.find(op->id()) != mapped_grad_ops.end();
    };
    for (auto& op_ref : topo_order) {
      if (mapped_grad_ops.find(op_ref.get()->id()) == mapped_grad_ops.end()) {
        continue;
      }
      auto& op_inputs = op_ref.get()->inputs();
      for (auto& input : op_inputs) {
        auto& op = input->producer();
        if (!op->is_bw_op()) {
          continue;
        }
        // As execution dependency, `input` should not rely on
        // any recomputed op that will be executed later and
        // any mapped grad op that relies on the recompute subgraph.
        if (HasFilterOpInPath(op, filter_fn, has_filter_op_map)) {
          continue;
        }
        first_mapped_grad_inputs.push_back(input);
      }
      if (!first_mapped_grad_inputs.empty()) {
        break;
      }
    }
    // Duplicate recomputed ops
    HT_LOG_DEBUG << "[Recompute] duplicate recomputed ops begin...";
    Op2OpMap origin_to_recomputed_map;
    // recompute pass is executed after instantiating exec graph,
    // so we ensure current graph is an exec graph
    auto& cur_exec_graph = reinterpret_cast<ExecutableGraph&>(Graph::GetGraph(Graph::cur_graph_ctx()));
    for (auto& op_opref : mapped_grad_ops) {
      auto& mapped_grad_op = op_opref.second.get();
      auto num_inputs = mapped_grad_op->num_inputs();
      for (int i = 0; i < num_inputs; i++) {
        auto& input = mapped_grad_op->input(i);
        auto& input_op = input->producer();
        if (filtered_recomputed_ops.find(input_op->id()) != filtered_recomputed_ops.end()) {
          auto out_idx = get_out_idx_of(input_op, input);
          HT_ASSERT(out_idx != -1)
            << "Cannot find input " << input << " in the outputs of recomputed op " << input_op;
          auto& recomputed_op = DuplicateRecomputedOp(input_op, filtered_recomputed_ops,
                                                      first_mapped_grad_inputs, origin_to_recomputed_map, cur_exec_graph);
          HT_LOG_DEBUG << "[Recompute] replacing mapped_grad_op " << mapped_grad_op << " input[" << i
                      << "] with recomputed_op " << recomputed_op << " output[" << out_idx << "]...";
          mapped_grad_op.get()->ReplaceInput(i, recomputed_op->output(out_idx));
        }
      }
    }
  }
}

} // namespace graph
} // namespace hetu